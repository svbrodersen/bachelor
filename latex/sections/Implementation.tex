\twocolumn[\section{Implementation}]
The implmentations created as part of this bachorlor thesis aimed
to make use of the LLVM compiler infastructure.
LLVM is a collection of modular and reusable compiler and toolchain technologies,
most notably for this project is the clang compiler and
lldb debugger. Furthermore, qemu will be used extensively while testing the
implementations.

\subsection{Dependencies}
\subsubsection*{QEMU}
\begin{lstlisting}[caption=Installing QEMU, float=*, label=lst:qemu_install]
git clone git clone https://github.com/qemu/qemu  # Clone the qemu repo
./configure --target-list=riscv32-softmmu  # Configure the 32-bit RISC-V target
make -j $(nproc)  # build the project with all num cores jobs
sudo make install
\end{lstlisting}.
QEMU is a system emulator, which has the capabilities of emulating both a 32-bit
and 64-bit RISC-V CPU\cite{QEMU}.
Following the instructions by RISC-V's getting started guide
we can build the QEMU RISC-V system emulators by running the code
provided in Listing~\ref{lst:qemu_install}\cite{RISC-V_GS}.\footnote{Once
installed make sure to add both llvm and riscv gnu toolchain
to path. Both should be installed in the /opt/ folder.}

\subsubsection{Installing LLVM compiler infastructure}
\begin{lstlisting}[caption=Installing LLVM compiler infastructure with RISC-V
32-bit as native target., float=*, label=lst:llvm_install]
# Dependencies
sudo apt-get -y install \
  binutils build-essential libtool texinfo \
  gzip zip unzip patchutils curl git \
  make cmake ninja-build automake bison flex gperf \
  grep sed gawk python bc \
  zlib1g-dev libexpat1-dev libmpc-dev \
  libglib2.0-dev libfdt-dev libpixman-1-dev

# Installing the RISC-V-gnu-toolchain
git clone https://github.com/riscv-collab/riscv-gnu-toolchain  # clone
riscv-gnu-toolchain
cd riscv-gnu-toolchain  # change directory
./configure --prefix=/opt/riscv --with-arch=rv32gc -disable-linux --enable-llvm
# prefix is install path used
sudo make -j$(nproc)
cd ..

# Installing LLVM
git clone https://github.com/llvm/llvm-project.git # clone llvm-project
cd llvm-project
mkdir build
pushd build
sudo cmake -S ../llvm -G Ninja \
-DCMAKE_BUILD_TYPE="Release" -DBUILD_SHARED_LIBS=True \
-DLLVM_BUILD_TESTS=False \
-DLLVM_ENABLE_PROJECTS="clang;clang-tools-extra;lld" \
-DCMAKE_INSTALL_PREFIX=/opt/llvm \
-DLLVM_TARGETS_TO_BUILD="RISCV"
sudo cmake --build . --target install
popd
\end{lstlisting}

\subsubsection*{LLVM and RISC-V-gnu-toolchain}
Although the LLVM clang compiler comes with an available crosscompiler, I found
that it often caused issues with missing header files compatible with my
implementation. Furthermore, the lldb debugger was unable to provide a working
debugger for the multicore remote debugging on QEMU. These are issues, which
might only be affecting me, as information revolving the issues were scarce. As
such, the following steps of building llvm and the RISC-V 32-bit gdb might be
obsolete, but are left here as a known working toolchain. Running the code in
Listing~\ref{lst:llvm_install} installs a RISC-V compatible clang compiler and gdb debugger in
the /opt/riscv/ directory. For the use outside this folder, make sure to add it
to PATH.


\subsection{Creating a linker script}
The linker script is used to tell the linker which parts of the file to include
in the final output file, as well as where each section is stored in memory. As
we are working on an embedded system, we have to stray from the default and
create our own linker script. The clang uses the LLVM lld linker, which is
compatible with the general linker scripts implementations of the GNU ld linker
\cite{llvm-org-linker}. Thus, we can make use of the GNU ld manual for modifying
the linker script in freeRTOS for our bare metal application instead of writing
the entire thing from scratch \cite{GNU-linker}.

memory@80000000 {
  device_type = "memory";
  reg = <0x00 0x80000000 0x00 0x8000000>
};
\end{lstlisting}
With the information previously provided, we know that the starting
address of the memory section is at address $0x00 + 0x80000000 = 0x80000000$ and has a size of
$0x00 + 0x8000000$ bytes, which is equivalent to 128MB.

\subsubsection{Creating a linker script}
The linker script is used to tell the linker which parts of the file to include
in the final output file, aswell as where each section is stored in memory. As
we are working on an embedded system, we have to stray from the default and
create our own linker script. The clang uses the llvm lld linker, which is compatible
with the general linker scripts implementations of the GNU ld linker\cite{llvm-org-linker}.
Thus, we can make use of the GNU ld manual for creating our linker script\cite{GNU-linker}.
\begin{lstlisting}
OUTPUT_ARCH('riscv')
ENTRY(_start)

MEMORY
{
/* Fake ROM area */
rom (rxa) : ORIGIN = 0x80000000, LENGTH = 1M
ram (wxa) : ORIGIN = 0x80100000, LENGTH = 127M
}
\end{lstlisting}
First, we must specify that we want the RISC-V architecture and designate the entry point
of the program at a function named "\_start," which we will define later.
Second, we define the MEMORY area to consist of both a writable memory region and a read-only
memory region. We name these regions 'ram' and 'rom,' respectively. With that we move on to define the SECTIONS element of the linker script.

\begin{lstlisting}
  SECTIONS
  {
    .text : ALIGN(CONSTANT(MAXPAGESIZE))
    {
    *(.text .text.*)
  } > rom

  .rodata : ALIGN(CONSTANT(MAXPAGESIZE))
  {
    *(.rdata)
    *(.rodata .rodata.*)
  } > rom

  .data : ALIGN(CONSTANT(MAXPAGESIZE))
  {
    *(.data .data.*)
    /*RISCV convention to have __global_pointer aligned to 8 bytes*/
    . = ALIGN(8);
    PROVIDE( __global_pointer$ = . + 0x800 );
  } > ram

  .bss : ALIGN(CONSTANT(MAXPAGESIZE))
  {
    *(.bss .bss.*)
  } > ram

  /* It is standard to have
  the stack aligned to 16 bytes*/
  . = ALIGN(16);
  _end = .;

  .stack : ALIGN(CONSTANT(MAXPAGESIZE))
  {
    . = ALIGN(8);
    PROVIDE(_stack_start = .);
    PROVIDE(_stack_top = ORIGIN(ram) + LENGTH(ram));
  } > ram
}
\end{lstlisting}
The text, rodata, data and bss sections follows the same general procedure. We
align the section to the maximum size of a page, and the match all the data
which we care about for the given sections. By specifying the > rom, we tell the
linker to save the given section in the rom section and the same is true for the
> ram. From the Figure~\ref{fig:mem_layout}, we can see the ram and rom
correspond to the ROM and RAM section of the figure.\footnote{rom stands for
  read-only memory, and ram stands for random-access memory. Generally it is not
necesarrily needed to split the two up as done here, but it is a good practise
to seperate what can change and what can not change in memory.}

In the data section, we also provide a global pointer, which is used to access
global variables within our later code implementation. The global pointer is
used together with an offset to save global variables. As such we allow for
0x800=2048 bytes of global variables. With the implementation being quite
reliant on global variables, it might need to be increased for lists of large
sizes.

The last section is the .stack section. We align the starting of the
\_stack\_start with 8 bytes. Generally not necesarry in this instance, but stil
a good custom. This is point from where each thread stack will be allocated.
Next, we specify that the \_stack\_top will reside at the end of the ram
section, such that we with an offset can allocate a stack for each core.

\subsection{Getting into the main function}
In the linker script we specified the entry point of our program as \_start. Next up
is implementing said entry point in assembly. Within a new assembly file we add the following.
\begin{lstlisting}[numbers=left]
.extern main
.section .init
.globl _start
.type _start,@function
#include "../include/defines.h"

_start:
  .cfi_startproc
  .cfi_undefined ra
  .option push
  .option norelax
  la gp, __global_pointer$
  .option pop
  // load _stack_top into the sp register
  la sp, _stack_top
  csrr a0, mhartid
  bnez a0, 2f
  1:
    // argc, argv is 0 and jump to main
    li  a0, 0
    li  a1, 0
    jal main
  1:
    // loop
    j 1b

  2:
    csrr a0, mhartid
    la sp, _stack_top
    la t1, 2048
    li t0, 0
  1:
    andi sp, sp, -16
    beq a0, t0, 1f
    sub sp, sp, t1
    addi t0, t0, 1
    j 1b
  1:
    // argc, argv is 0 and jump to main
    li  a0, 0
    li  a1, 0
    jal secondary_main
  1:
    // loop
    j 1b

    .cfi_endproc  // We should never really reach this
\end{lstlisting}
First we specify that externally there will be implemented a main entry point. Next we tell the
linker to save the following code in the .init section and initialize a global label \_start,
and note that it is a function.

Next the \_start is defined, and define .cfi\_startproc such that we have an entry in the
.eh\_frame. Next we define the return address register(ra) as being undefined, as we are in
the start of the entire program. Since the linker usually relaxes addressing sequences to
shorter GP-relative sequences when possible, the initial load of GP must not be relaxed
\cite{GNU_BIN}. However, we do not need the same for loading the \_stack\_top into the sp
register, and then also save it in the s0 register, which stores the frame pointer.
Then the last step is loading 0 into argc, argv and envp and the jump to the externally
defined main function.

\subsection{libucontext}
